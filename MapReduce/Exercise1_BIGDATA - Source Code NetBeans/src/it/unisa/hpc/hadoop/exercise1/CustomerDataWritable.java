/**
 * Course: High Performance Computing 2023/2024
 *
 * Lecturer: Giuseppe D'Aniello      gidaniello@unisa.it
 *
 * Student and Creator:
 * Agostino Cardamone       0622702276      a.cardamone7@studenti.unisa.it
 *
 * Source Code of Hadoop MapReduce Exercise 1 Solution.
 *
 *                        ASSIGNMENT:
 * 
 * This Java code is designed to analyze a dataset containing sales information from a store, 
 * providing details about the sold products. The dataset encompasses various fields, 
 * including order details, customer information, and product specifics. 
 * Below is an overview of the available fields:
 * - Order ID: A unique identifier for each order.
 * - Customer ID: A unique identifier for each customer.
 * - Order Date: The date of the order placement.
 * - Ship Date: The date the order was shipped.
 * - Ship Mode: The shipping mode for the order (e.g., standard, same-day).
 * - Segment: The customer segment (e.g., Consumer, Corporate, Home Office).
 * - Region: The region where the customer is located (e.g., West, Central, East).
 * - Category: The category of the product purchased (e.g., Furniture, Technology, Office Supplies).
 * - Sub-Category: The sub-category of the product purchased (e.g., Chairs, Desktops, Paper).
 * - Product Name: The name of the product purchased.
 * - Sales: The sales revenue for the product purchased.
 * - Quantity: The number of units of the product purchased.
 * - Discount: The discount applied to the product purchased.
 * - Profit: The profit generated by the product purchased.
 *
 * Exercise 1 – Map Reduce:
 * Implement a Hadoop Map Reduce program to analyze the dataset in a different manner from the second exercise. 
 * This could involve generating statistics, creating rankings, calculating indices, or any unique approach.
 *
 * Exercise 2 – Spark:
 * Determine which region has the highest sales and which region has the lowest sales using Spark. 
 * This analysis aims to provide insights into regional sales performance within the dataset.
 *
 */
package it.unisa.hpc.hadoop.exercise1;

import org.apache.hadoop.io.Text;
import org.apache.hadoop.io.Writable;

import java.io.DataInput;
import java.io.DataOutput;
import java.io.IOException;
import org.apache.hadoop.io.DoubleWritable;

/**
 * Represents a custom Writable for Hadoop MapReduce.
 * It encapsulates order date, sales, and customer segment.
 *
 * @author agost
 */
public class CustomerDataWritable implements Writable {
    private Text orderDate;
    private DoubleWritable sales;
    private Text customerSegment;

    // Default constructor
    public CustomerDataWritable() {
        set(new Text(), new DoubleWritable(), new Text());
    }

    // Parameterized constructor
    public CustomerDataWritable(String orderDate, double sales, String customerSegment) {
        set(new Text(orderDate), new DoubleWritable(sales), new Text(customerSegment));
    }

    // Setter method
    public void set(Text orderDate, DoubleWritable sales, Text customerSegment) {
        this.orderDate = orderDate;
        this.sales = sales;
        this.customerSegment = customerSegment;
    }

    // Getter methods
    public Text getOrderDate() {
        return orderDate;
    }

    public DoubleWritable getSales() {
        return sales;
    }

    public Text getCustomerSegment() {
        return customerSegment;
    }

    // Serialization method
    @Override
    public void write(DataOutput out) throws IOException {
        orderDate.write(out);
        sales.write(out);
        customerSegment.write(out);
    }

    // Deserialization method
    @Override
    public void readFields(DataInput in) throws IOException {
        orderDate.readFields(in);
        sales.readFields(in);
        customerSegment.readFields(in);
    }
}